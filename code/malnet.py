import tensorflow as tf
from random import shuffle
import numpy as np
from scipy import sparse
from ml_robot import SKTFModel
import os
import warnings
warnings.filterwarnings("ignore")

# assume all features are cat features
# features should be label encoded
class MalNN(SKTFModel):

    def __init__(self,**kwargs):
        super().__init__(**kwargs)
        self.idx = '%s_%s'%(self.idx,os.environ["CUDA_VISIBLE_DEVICES"])
        print(self.idx)
        self.voc_size = None

    def get_voc_size(self):
        if self.voc_size is not None:
            return self.voc_size,self.emd_size
        N = self.params['catfeas']
        self.voc_size = np.max(self.X[:,:N],axis=0)+1
        self.emd_size = [1 if i<=2 else min(int(1+np.log1p(i)),8) for i in self.voc_size]
        #self.emd_size = [4]*len(self.voc_size)
        print('emd',self.emd_size)
        return self.voc_size,self.emd_size

    def _build(self):
        netname = 'CatNN'

        voc_size,emd_size = self.get_voc_size()
        Hs = self.params['Hs']
        D = self.params.get('drop_prob',0.25)
        C = self.params.get('classes',1)

        As = ['relu' for i in Hs]
        Ds = [D for i in Hs]
        Ds[-1] = 0

        print(self.X.shape)
        SF = self.X.shape[1]
        N = self.params['catfeas'] # a list

        if isinstance(emd_size,list)==False:
            emd_size = [emd_size for i in range(N)]
        self.inputs = tf.placeholder(tf.float32,shape=[None,SF])
        cat = self.inputs[:,:N]
        cat = tf.cast(cat,tf.int32)
        num = self.inputs[:,N:]
  
        B = tf.shape(self.inputs)[0]
        net = self.inputs
        with tf.variable_scope(netname):
            cxs = []
            for c,net in enumerate(tf.split(cat,N,axis=1)):
                name = 'cat_%d'%c
                tmp = self._get_embedding("%s/%s"%(netname,name),net,voc_size[c],emd_size[c])
                cxs.append(tf.reshape(tmp,[B,emd_size[c]]))
            cnet = tf.concat(cxs,axis=1)
            cnet_out = self.params.get('get_embedding',0)
            if cnet_out:
                #self.params['objective'] = 'regression'
                return cnet
            net = self._fc(num, Hs[-1], layer_name='%s/num'%(netname),activation='relu')
            #net = tf.concat([cnet,num],axis=1)
            #net = cnet
            for c,(h,a,d) in enumerate(zip(Hs,As,Ds)):
                net = self.fcblock(net,h,netname,c+1,a,d)
            net1 = self.fcblock(cnet,h,netname,c+2,a,d)
            net = tf.concat([net,net1],axis=1)
            net = self._fc(net, C, layer_name='%s/out'%(netname))    
        return tf.squeeze(net)

    def fcblock(self,net,H,name,idx,activation,drop_prob,norm=False,tag=''):
        net = self._fc(net, H, layer_name='%s/%sfc%d'%(name,tag,idx))#,use_mask=True,thresh=1e-4)
        if norm:
            net = self._batch_normalization(net, layer_name='%s/%sbn%d'%(name,tag,idx))
        net = self._activate(net, activation)
        if drop_prob>0:
            net = self._dropout(net,1-drop_prob)
        return net

if __name__ == '__main__':
    x = [[1,2,3,4],[1,3,5,7],[2,3,4,5],[6,7,8,9],[0.1,0.2,0.3,0.4]]
    x = np.array(x).T
    y = np.array([1,0,1,0])
    print(x.shape,y.shape,type(x),isinstance(x,sparse.csr_matrix))
    nn = NumCatNN(batch_size=2,objective='regression',metric='rmse',
        voc_size = [5,8,6,10],emd_size=[4]*4,learning_rate=0.001,
        catfeas = [0,1,2,3], numfeas = [4]
    )
    nn.fit(x,y)

